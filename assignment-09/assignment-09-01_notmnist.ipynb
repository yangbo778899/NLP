{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "from IPython.display import display, Image\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MACHINE_LOCAL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://commondatastorage.googleapis.com/books1000/'\n",
    "last_percent_reported = None\n",
    "if MACHINE_LOCAL:\n",
    "    data_root = '/Users/yangbo/working/机器学习/深度学习/作业/NLP/NLP/assignment-09/res/' # Change me to store data elsewhere\n",
    "else:\n",
    "    data_root = '/data/zz/nlp/l9/res/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified /data/zz/nlp/l9/res/notMNIST_large.tar.gz\n",
      "Found and verified /data/zz/nlp/l9/res/notMNIST_small.tar.gz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def download_progress_hook(count, blockSize, totalSize):\n",
    "  \"\"\"A hook to report the progress of a download. This is mostly intended for users with\n",
    "  slow internet connections. Reports every 5% change in download progress.\n",
    "  \"\"\"\n",
    "  global last_percent_reported\n",
    "  percent = int(count * blockSize * 100 / totalSize)\n",
    "\n",
    "  if last_percent_reported != percent:\n",
    "    if percent % 5 == 0:\n",
    "      sys.stdout.write(\"%s%%\" % percent)\n",
    "      sys.stdout.flush()\n",
    "    else:\n",
    "      sys.stdout.write(\".\")\n",
    "      sys.stdout.flush()\n",
    "      \n",
    "    last_percent_reported = percent\n",
    "        \n",
    "def maybe_download(filename, expected_bytes, force=False):\n",
    "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "  dest_filename = os.path.join(data_root, filename)\n",
    "  if force or not os.path.exists(dest_filename):\n",
    "    print('Attempting to download:', filename) \n",
    "    filename, _ = urlretrieve(url + filename, dest_filename, reporthook=download_progress_hook)\n",
    "    print('\\nDownload Complete!')\n",
    "  statinfo = os.stat(dest_filename)\n",
    "  if statinfo.st_size == expected_bytes:\n",
    "    print('Found and verified', dest_filename)\n",
    "  else:\n",
    "    raise Exception(\n",
    "      'Failed to verify ' + dest_filename + '. Can you get to it with a browser?')\n",
    "  return dest_filename\n",
    "\n",
    "train_filename = maybe_download('notMNIST_large.tar.gz', 247336696)\n",
    "test_filename = maybe_download('notMNIST_small.tar.gz', 8458043)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_filename = data_root +'notMNIST_large.tar.gz'\n",
    "test_filename = data_root + 'notMNIST_small.tar.gz'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data for /data/zz/nlp/l9/res/notMNIST_large. This may take a while. Please wait.\n",
      "['/data/zz/nlp/l9/res/notMNIST_large/A', '/data/zz/nlp/l9/res/notMNIST_large/B', '/data/zz/nlp/l9/res/notMNIST_large/C', '/data/zz/nlp/l9/res/notMNIST_large/D', '/data/zz/nlp/l9/res/notMNIST_large/E', '/data/zz/nlp/l9/res/notMNIST_large/F', '/data/zz/nlp/l9/res/notMNIST_large/G', '/data/zz/nlp/l9/res/notMNIST_large/H', '/data/zz/nlp/l9/res/notMNIST_large/I', '/data/zz/nlp/l9/res/notMNIST_large/J']\n",
      "Extracting data for /data/zz/nlp/l9/res/notMNIST_small. This may take a while. Please wait.\n",
      "['/data/zz/nlp/l9/res/notMNIST_small/A', '/data/zz/nlp/l9/res/notMNIST_small/B', '/data/zz/nlp/l9/res/notMNIST_small/C', '/data/zz/nlp/l9/res/notMNIST_small/D', '/data/zz/nlp/l9/res/notMNIST_small/E', '/data/zz/nlp/l9/res/notMNIST_small/F', '/data/zz/nlp/l9/res/notMNIST_small/G', '/data/zz/nlp/l9/res/notMNIST_small/H', '/data/zz/nlp/l9/res/notMNIST_small/I', '/data/zz/nlp/l9/res/notMNIST_small/J']\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "np.random.seed(133)\n",
    "\n",
    "def maybe_extract(filename, force=False):\n",
    "  root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
    "  if os.path.isdir(root) and not force:\n",
    "    # You may override by setting force=True.\n",
    "    print('%s already present - Skipping extraction of %s.' % (root, filename))\n",
    "  else:\n",
    "    print('Extracting data for %s. This may take a while. Please wait.' % root)\n",
    "    tar = tarfile.open(filename)\n",
    "    sys.stdout.flush()\n",
    "    tar.extractall(data_root)\n",
    "    tar.close()\n",
    "  data_folders = [\n",
    "    os.path.join(root, d) for d in sorted(os.listdir(root))\n",
    "    if os.path.isdir(os.path.join(root, d))]\n",
    "  if len(data_folders) != num_classes:\n",
    "    raise Exception(\n",
    "      'Expected %d folders, one per class. Found %d instead.' % (\n",
    "        num_classes, len(data_folders)))\n",
    "  print(data_folders)\n",
    "  return data_folders\n",
    "  \n",
    "train_folders = maybe_extract(train_filename)\n",
    "test_folders = maybe_extract(test_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/zz/nlp/l9/res/notMNIST_small/A',\n",
       " '/data/zz/nlp/l9/res/notMNIST_small/B',\n",
       " '/data/zz/nlp/l9/res/notMNIST_small/C',\n",
       " '/data/zz/nlp/l9/res/notMNIST_small/D',\n",
       " '/data/zz/nlp/l9/res/notMNIST_small/E',\n",
       " '/data/zz/nlp/l9/res/notMNIST_small/F',\n",
       " '/data/zz/nlp/l9/res/notMNIST_small/G',\n",
       " '/data/zz/nlp/l9/res/notMNIST_small/H',\n",
       " '/data/zz/nlp/l9/res/notMNIST_small/I',\n",
       " '/data/zz/nlp/l9/res/notMNIST_small/J']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folders\n",
    "test_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling /data/zz/nlp/l9/res/notMNIST_large/A.pickle.\n",
      "/data/zz/nlp/l9/res/notMNIST_large/A\n",
      "Could not read: /data/zz/nlp/l9/res/notMNIST_large/A/Um9tYW5hIEJvbGQucGZi.png : Could not find a format to read the specified file in mode 'i' - it's ok, skipping.\n",
      "Could not read: /data/zz/nlp/l9/res/notMNIST_large/A/SG90IE11c3RhcmQgQlROIFBvc3Rlci50dGY=.png : Could not find a format to read the specified file in mode 'i' - it's ok, skipping.\n",
      "Could not read: /data/zz/nlp/l9/res/notMNIST_large/A/RnJlaWdodERpc3BCb29rSXRhbGljLnR0Zg==.png : Could not find a format to read the specified file in mode 'i' - it's ok, skipping.\n",
      "Full dataset tensor: (52909, 28, 28)\n",
      "Mean: -0.1282502\n",
      "Standard deviation: 0.44312108\n",
      "Pickling /data/zz/nlp/l9/res/notMNIST_large/B.pickle.\n",
      "/data/zz/nlp/l9/res/notMNIST_large/B\n",
      "Could not read: /data/zz/nlp/l9/res/notMNIST_large/B/TmlraXNFRi1TZW1pQm9sZEl0YWxpYy5vdGY=.png : Could not find a format to read the specified file in mode 'i' - it's ok, skipping.\n",
      "Full dataset tensor: (52911, 28, 28)\n",
      "Mean: -0.007563037\n",
      "Standard deviation: 0.45449135\n",
      "Pickling /data/zz/nlp/l9/res/notMNIST_large/C.pickle.\n",
      "/data/zz/nlp/l9/res/notMNIST_large/C\n",
      "Full dataset tensor: (52912, 28, 28)\n",
      "Mean: -0.14225805\n",
      "Standard deviation: 0.4398061\n",
      "Pickling /data/zz/nlp/l9/res/notMNIST_large/D.pickle.\n",
      "/data/zz/nlp/l9/res/notMNIST_large/D\n",
      "Could not read: /data/zz/nlp/l9/res/notMNIST_large/D/VHJhbnNpdCBCb2xkLnR0Zg==.png : Could not find a format to read the specified file in mode 'i' - it's ok, skipping.\n",
      "Full dataset tensor: (52911, 28, 28)\n",
      "Mean: -0.057367764\n",
      "Standard deviation: 0.45564747\n",
      "Pickling /data/zz/nlp/l9/res/notMNIST_large/E.pickle.\n",
      "/data/zz/nlp/l9/res/notMNIST_large/E\n",
      "Full dataset tensor: (52912, 28, 28)\n",
      "Mean: -0.06989894\n",
      "Standard deviation: 0.45294157\n",
      "Pickling /data/zz/nlp/l9/res/notMNIST_large/F.pickle.\n",
      "/data/zz/nlp/l9/res/notMNIST_large/F\n",
      "Full dataset tensor: (52912, 28, 28)\n",
      "Mean: -0.12558322\n",
      "Standard deviation: 0.44708985\n",
      "Pickling /data/zz/nlp/l9/res/notMNIST_large/G.pickle.\n",
      "/data/zz/nlp/l9/res/notMNIST_large/G\n",
      "Full dataset tensor: (52912, 28, 28)\n",
      "Mean: -0.09458162\n",
      "Standard deviation: 0.44624022\n",
      "Pickling /data/zz/nlp/l9/res/notMNIST_large/H.pickle.\n",
      "/data/zz/nlp/l9/res/notMNIST_large/H\n",
      "Full dataset tensor: (52912, 28, 28)\n",
      "Mean: -0.06852219\n",
      "Standard deviation: 0.4542314\n",
      "Pickling /data/zz/nlp/l9/res/notMNIST_large/I.pickle.\n",
      "/data/zz/nlp/l9/res/notMNIST_large/I\n",
      "Full dataset tensor: (52912, 28, 28)\n",
      "Mean: 0.030786244\n",
      "Standard deviation: 0.4688984\n",
      "Pickling /data/zz/nlp/l9/res/notMNIST_large/J.pickle.\n",
      "/data/zz/nlp/l9/res/notMNIST_large/J\n",
      "Full dataset tensor: (52911, 28, 28)\n",
      "Mean: -0.15335837\n",
      "Standard deviation: 0.44365638\n",
      "Pickling /data/zz/nlp/l9/res/notMNIST_small/A.pickle.\n",
      "/data/zz/nlp/l9/res/notMNIST_small/A\n",
      "Could not read: /data/zz/nlp/l9/res/notMNIST_small/A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png : Could not find a format to read the specified file in mode 'i' - it's ok, skipping.\n",
      "Full dataset tensor: (1872, 28, 28)\n",
      "Mean: -0.13262637\n",
      "Standard deviation: 0.44512793\n",
      "Pickling /data/zz/nlp/l9/res/notMNIST_small/B.pickle.\n",
      "/data/zz/nlp/l9/res/notMNIST_small/B\n",
      "Full dataset tensor: (1873, 28, 28)\n",
      "Mean: 0.0053560827\n",
      "Standard deviation: 0.45711535\n",
      "Pickling /data/zz/nlp/l9/res/notMNIST_small/C.pickle.\n",
      "/data/zz/nlp/l9/res/notMNIST_small/C\n",
      "Full dataset tensor: (1873, 28, 28)\n",
      "Mean: -0.14152054\n",
      "Standard deviation: 0.4426903\n",
      "Pickling /data/zz/nlp/l9/res/notMNIST_small/D.pickle.\n",
      "/data/zz/nlp/l9/res/notMNIST_small/D\n",
      "Full dataset tensor: (1873, 28, 28)\n",
      "Mean: -0.049216665\n",
      "Standard deviation: 0.459759\n",
      "Pickling /data/zz/nlp/l9/res/notMNIST_small/E.pickle.\n",
      "/data/zz/nlp/l9/res/notMNIST_small/E\n",
      "Full dataset tensor: (1873, 28, 28)\n",
      "Mean: -0.05991477\n",
      "Standard deviation: 0.4573496\n",
      "Pickling /data/zz/nlp/l9/res/notMNIST_small/F.pickle.\n",
      "/data/zz/nlp/l9/res/notMNIST_small/F\n",
      "Could not read: /data/zz/nlp/l9/res/notMNIST_small/F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png : Could not find a format to read the specified file in mode 'i' - it's ok, skipping.\n",
      "Full dataset tensor: (1872, 28, 28)\n",
      "Mean: -0.118185334\n",
      "Standard deviation: 0.45227867\n",
      "Pickling /data/zz/nlp/l9/res/notMNIST_small/G.pickle.\n",
      "/data/zz/nlp/l9/res/notMNIST_small/G\n",
      "Full dataset tensor: (1872, 28, 28)\n",
      "Mean: -0.092550315\n",
      "Standard deviation: 0.44900584\n",
      "Pickling /data/zz/nlp/l9/res/notMNIST_small/H.pickle.\n",
      "/data/zz/nlp/l9/res/notMNIST_small/H\n",
      "Full dataset tensor: (1872, 28, 28)\n",
      "Mean: -0.05868924\n",
      "Standard deviation: 0.45875892\n",
      "Pickling /data/zz/nlp/l9/res/notMNIST_small/I.pickle.\n",
      "/data/zz/nlp/l9/res/notMNIST_small/I\n",
      "Full dataset tensor: (1872, 28, 28)\n",
      "Mean: 0.052645072\n",
      "Standard deviation: 0.47189352\n",
      "Pickling /data/zz/nlp/l9/res/notMNIST_small/J.pickle.\n",
      "/data/zz/nlp/l9/res/notMNIST_small/J\n",
      "Full dataset tensor: (1872, 28, 28)\n",
      "Mean: -0.15168916\n",
      "Standard deviation: 0.44801366\n"
     ]
    }
   ],
   "source": [
    "image_size = 28  # Pixel width and height.\n",
    "pixel_depth = 255.0  # Number of levels per pixel.\n",
    "\n",
    "def load_letter(folder, min_num_images):\n",
    "  \"\"\"Load the data for a single letter label.\"\"\"\n",
    "  image_files = os.listdir(folder)\n",
    "  dataset = np.ndarray(shape=(len(image_files), image_size, image_size),\n",
    "                         dtype=np.float32)\n",
    "  print(folder)\n",
    "  num_images = 0\n",
    "  for image in image_files:\n",
    "    image_file = os.path.join(folder, image)\n",
    "    try:\n",
    "      image_data = (imageio.imread(image_file).astype(float) - \n",
    "                    pixel_depth / 2) / pixel_depth\n",
    "      if image_data.shape != (image_size, image_size):\n",
    "        raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "      dataset[num_images, :, :] = image_data\n",
    "      num_images = num_images + 1\n",
    "    except (IOError, ValueError) as e:\n",
    "      print('Could not read:', image_file, ':', e, '- it\\'s ok, skipping.')\n",
    "    \n",
    "  dataset = dataset[0:num_images, :, :]\n",
    "  if num_images < min_num_images:\n",
    "    raise Exception('Many fewer images than expected: %d < %d' %\n",
    "                    (num_images, min_num_images))\n",
    "    \n",
    "  print('Full dataset tensor:', dataset.shape)\n",
    "  print('Mean:', np.mean(dataset))\n",
    "  print('Standard deviation:', np.std(dataset))\n",
    "  return dataset\n",
    "        \n",
    "def maybe_pickle(data_folders, min_num_images_per_class, force=False):\n",
    "  dataset_names = []\n",
    "  for folder in data_folders:\n",
    "    set_filename = folder + '.pickle'\n",
    "    dataset_names.append(set_filename)\n",
    "    if os.path.exists(set_filename) and not force:\n",
    "      # You may override by setting force=True.\n",
    "      print('%s already present - Skipping pickling.' % set_filename)\n",
    "    else:\n",
    "      print('Pickling %s.' % set_filename)\n",
    "      dataset = load_letter(folder, min_num_images_per_class)\n",
    "      try:\n",
    "        with open(set_filename, 'wb') as f:\n",
    "          pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "      except Exception as e:\n",
    "        print('Unable to save data to', set_filename, ':', e)\n",
    "  \n",
    "  return dataset_names\n",
    "\n",
    "train_datasets = maybe_pickle(train_folders, 45000)\n",
    "test_datasets = maybe_pickle(test_folders, 1800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/zz/nlp/l9/res/notMNIST_large/A.pickle',\n",
       " '/data/zz/nlp/l9/res/notMNIST_large/B.pickle',\n",
       " '/data/zz/nlp/l9/res/notMNIST_large/C.pickle',\n",
       " '/data/zz/nlp/l9/res/notMNIST_large/D.pickle',\n",
       " '/data/zz/nlp/l9/res/notMNIST_large/E.pickle',\n",
       " '/data/zz/nlp/l9/res/notMNIST_large/F.pickle',\n",
       " '/data/zz/nlp/l9/res/notMNIST_large/G.pickle',\n",
       " '/data/zz/nlp/l9/res/notMNIST_large/H.pickle',\n",
       " '/data/zz/nlp/l9/res/notMNIST_large/I.pickle',\n",
       " '/data/zz/nlp/l9/res/notMNIST_large/J.pickle']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_pickle = data_root + 'notMNIST_large/A.pickle'\n",
    "try:\n",
    "    with open(file_name_pickle, 'rb') as f:\n",
    "        data_pickle_a = pickle.load(f)\n",
    "        \n",
    "except Exception as e:\n",
    "    print('Unable to open data to', file_name_pickle, ':', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1c69716c18>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_pickle_a[1,:,:]\n",
    "plt.imshow(data_pickle_a[100,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/zz/nlp/l9/res/notMNIST_large/A.pickle'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/zz/nlp/l9/res/notMNIST_small/A.pickle',\n",
       " '/data/zz/nlp/l9/res/notMNIST_small/B.pickle',\n",
       " '/data/zz/nlp/l9/res/notMNIST_small/C.pickle',\n",
       " '/data/zz/nlp/l9/res/notMNIST_small/D.pickle',\n",
       " '/data/zz/nlp/l9/res/notMNIST_small/E.pickle',\n",
       " '/data/zz/nlp/l9/res/notMNIST_small/F.pickle',\n",
       " '/data/zz/nlp/l9/res/notMNIST_small/G.pickle',\n",
       " '/data/zz/nlp/l9/res/notMNIST_small/H.pickle',\n",
       " '/data/zz/nlp/l9/res/notMNIST_small/I.pickle',\n",
       " '/data/zz/nlp/l9/res/notMNIST_small/J.pickle']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_pickle = data_root + 'notMNIST_small/A.pickle'\n",
    "try:\n",
    "    with open(file_name_pickle, 'rb') as f:\n",
    "        data_small_a = pickle.load(f)        \n",
    "except Exception as e:\n",
    "    print('Unable to open data to', file_name_pickle, ':', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/zz/nlp/l9/res/notMNIST_small/A.pickle'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1c68d3f908>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data_small_a[60,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (200000, 28, 28) (200000,)\n",
      "Validation: (10000, 28, 28) (10000,)\n",
      "Testing: (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "def make_arrays(nb_rows, img_size):\n",
    "  if nb_rows:\n",
    "    dataset = np.ndarray((nb_rows, img_size, img_size), dtype=np.float32)\n",
    "    labels = np.ndarray(nb_rows, dtype=np.int32)\n",
    "  else:\n",
    "    dataset, labels = None, None\n",
    "  return dataset, labels\n",
    "\n",
    "def merge_datasets(pickle_files, train_size, valid_size=0):\n",
    "  num_classes = len(pickle_files)\n",
    "  valid_dataset, valid_labels = make_arrays(valid_size, image_size)\n",
    "  train_dataset, train_labels = make_arrays(train_size, image_size)\n",
    "  vsize_per_class = valid_size // num_classes\n",
    "  tsize_per_class = train_size // num_classes\n",
    "    \n",
    "  start_v, start_t = 0, 0\n",
    "  end_v, end_t = vsize_per_class, tsize_per_class\n",
    "  end_l = vsize_per_class+tsize_per_class\n",
    "  for label, pickle_file in enumerate(pickle_files):       \n",
    "    try:\n",
    "      with open(pickle_file, 'rb') as f:\n",
    "        letter_set = pickle.load(f)\n",
    "        # let's shuffle the letters to have random validation and training set\n",
    "        np.random.shuffle(letter_set)\n",
    "        if valid_dataset is not None:\n",
    "          valid_letter = letter_set[:vsize_per_class, :, :]\n",
    "          valid_dataset[start_v:end_v, :, :] = valid_letter\n",
    "          valid_labels[start_v:end_v] = label\n",
    "          start_v += vsize_per_class\n",
    "          end_v += vsize_per_class\n",
    "                    \n",
    "        train_letter = letter_set[vsize_per_class:end_l, :, :]\n",
    "        train_dataset[start_t:end_t, :, :] = train_letter\n",
    "        train_labels[start_t:end_t] = label\n",
    "        start_t += tsize_per_class\n",
    "        end_t += tsize_per_class\n",
    "    except Exception as e:\n",
    "      print('Unable to process data from', pickle_file, ':', e)\n",
    "      raise\n",
    "    \n",
    "  return valid_dataset, valid_labels, train_dataset, train_labels\n",
    "            \n",
    "            \n",
    "train_size = 200000\n",
    "valid_size = 10000\n",
    "test_size = 10000\n",
    "\n",
    "valid_dataset, valid_labels, train_dataset, train_labels = merge_datasets(\n",
    "  train_datasets, train_size, valid_size)\n",
    "_, _, test_dataset, test_labels = merge_datasets(test_datasets, test_size)\n",
    "\n",
    "print('Training:', train_dataset.shape, train_labels.shape)\n",
    "print('Validation:', valid_dataset.shape, valid_labels.shape)\n",
    "print('Testing:', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize(dataset, labels):\n",
    "  permutation = np.random.permutation(labels.shape[0])\n",
    "  shuffled_dataset = dataset[permutation,:,:]\n",
    "  shuffled_labels = labels[permutation]\n",
    "  return shuffled_dataset, shuffled_labels\n",
    "train_dataset, train_labels = randomize(train_dataset, train_labels)\n",
    "test_dataset, test_labels = randomize(test_dataset, test_labels)\n",
    "valid_dataset, valid_labels = randomize(valid_dataset, valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (200000, 28, 28) (200000,)\n",
      "Validation: (10000, 28, 28) (10000,)\n",
      "Testing: (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('Training:', train_dataset.shape, train_labels.shape)\n",
    "print('Validation:', valid_dataset.shape, valid_labels.shape)\n",
    "print('Testing:', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/zz/nlp/l9/res/'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = os.path.join(data_root, 'notMNIST.pickle')\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'train_dataset': train_dataset,\n",
    "    'train_labels': train_labels,\n",
    "    'valid_dataset': valid_dataset,\n",
    "    'valid_labels': valid_labels,\n",
    "    'test_dataset': test_dataset,\n",
    "    'test_labels': test_labels,\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed pickle size: 690800506\n"
     ]
    }
   ],
   "source": [
    "statinfo = os.stat(pickle_file)\n",
    "print('Compressed pickle size:', statinfo.st_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6  逻辑回归训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clr = LogisticRegression(penalty = 'l2',solver='saga', verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、Full train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Python36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 198 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 198 seconds\n",
      "max_iter reached after 198 seconds\n",
      "max_iter reached after 343 seconds\n",
      "max_iter reached after 198 seconds\n",
      "max_iter reached after 197 seconds\n",
      "max_iter reached after 199 seconds\n",
      "max_iter reached after 198 seconds\n",
      "max_iter reached after 197 seconds\n",
      "max_iter reached after 199 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 35.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='saga', tol=0.0001, verbose=1,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clr.fit(train_dataset.reshape((-1, 28*28)), train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clr.predict(test_dataset.reshape((-1, 28*28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "probility = clr.predict_proba(test_dataset.reshape((-1, 28*28)))           #计算各测试样本基于概率的预测 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = clr.score(test_dataset.reshape((-1, 28*28)),test_labels,sample_weight=None)    #调用该对象的打分方法，计算出准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.892\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、100 train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Python36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/usr/local/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 1 seconds\n",
      "max_iter reached after 0 seconds\n",
      "max_iter reached after 0 seconds\n",
      "max_iter reached after 0 seconds\n",
      "max_iter reached after 0 seconds\n",
      "max_iter reached after 0 seconds\n",
      "max_iter reached after 0 seconds\n",
      "max_iter reached after 0 seconds\n",
      "max_iter reached after 0 seconds\n",
      "max_iter reached after 0 seconds\n",
      "Accuracy: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.9s finished\n"
     ]
    }
   ],
   "source": [
    "max_index = 100\n",
    "clr.fit(train_dataset[:max_index].reshape((-1, 28*28)), train_labels[:max_index])\n",
    "y_predict = clr.predict(test_dataset[:max_index].reshape((-1, 28*28)))\n",
    "probility = clr.predict_proba(test_dataset[:max_index].reshape((-1, 28*28)))           #计算各测试样本基于概率的预测 \n",
    "score = clr.score(test_dataset[:max_index].reshape((-1, 28*28)),test_labels[:max_index],sample_weight=None)    #调用该对象的打分方法，计算出准确率\n",
    "print('Accuracy:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、1000 train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Python36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 1 seconds\n",
      "max_iter reached after 1 seconds\n",
      "max_iter reached after 1 seconds\n",
      "max_iter reached after 1 seconds\n",
      "max_iter reached after 0 seconds\n",
      "max_iter reached after 1 seconds\n",
      "max_iter reached after 1 seconds\n",
      "max_iter reached after 1 seconds\n",
      "max_iter reached after 1 seconds\n",
      "Accuracy: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    9.1s finished\n"
     ]
    }
   ],
   "source": [
    "max_index = 1000\n",
    "clr.fit(train_dataset[:max_index].reshape((-1, 28*28)), train_labels[:max_index])\n",
    "y_predict = clr.predict(test_dataset[:max_index].reshape((-1, 28*28)))\n",
    "probility = clr.predict_proba(test_dataset[:max_index].reshape((-1, 28*28)))           #计算各测试样本基于概率的预测 \n",
    "score = clr.score(test_dataset[:max_index].reshape((-1, 28*28)),test_labels[:max_index],sample_weight=None)    #调用该对象的打分方法，计算出准确率\n",
    "print('Accuracy:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4、5000 train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Python36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Python36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 4 seconds\n",
      "max_iter reached after 5 seconds\n",
      "max_iter reached after 4 seconds\n",
      "max_iter reached after 5 seconds\n",
      "max_iter reached after 4 seconds\n",
      "max_iter reached after 5 seconds\n",
      "max_iter reached after 4 seconds\n",
      "max_iter reached after 5 seconds\n",
      "max_iter reached after 5 seconds\n",
      "Accuracy: 0.853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   45.6s finished\n"
     ]
    }
   ],
   "source": [
    "max_index = 5000\n",
    "clr.fit(train_dataset[:max_index].reshape((-1, 28*28)), train_labels[:max_index])\n",
    "y_predict = clr.predict(test_dataset[:max_index].reshape((-1, 28*28)))\n",
    "probility = clr.predict_proba(test_dataset[:max_index].reshape((-1, 28*28)))           #计算各测试样本基于概率的预测 \n",
    "score = clr.score(test_dataset[:max_index].reshape((-1, 28*28)),test_labels[:max_index],sample_weight=None)    #调用该对象的打分方法，计算出准确率\n",
    "print('Accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
